# 常见问题

## redis是单线程还是多线程

redis采用了多路复用技术，其中epoll就是多路复用器

### 工作流程

1. 无论是什么版本，工作线程就一个

2. 6.0以后出现了IO多线程

3. IO多线程其实指**客户端交互部分**的**网络IO交互处理模块多线程**，而非执行命令多线程。Redis6执行命令依然是单线程。

4. 单线程，满足redis的串行原子，只不过IO多线程后，吧输入/输出放到更多的线程里去并行，好处如下：

   1. 执行时间缩短，更快

   2. 更好的压榨系统及硬件的资源(网卡能够高效的使用)

==6以前的==

![image-20220220111915696](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220111915696.png)

单线程工作指的是客户端连接到内核后，内核会给每个连接提供输入输出队列，epoll作为多路复用器依赖于内核，仅仅起到告知读写事件的作用。redis工作线程开始运行时会查看是否有读写事件发生，读取到数据后进行计算，然后返回结果。有多个连接时，各个连接之间的操作是串行的。

为什么redis的事务是在失败之后还能继续执行？

redis中没有回滚，它是将你所有的事务都攒到队列中一次性执行的，分为准备阶段和执行阶段，在执行的过程中如果一个事务出错了，就会继续执行下一个事务。因此在redis中少使用事务，或在使用事务时尽量使用较少的指令，且尽量快

==6.0以后：==

![image-20220220114245564](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220114245564.png)

6.0以后的版本

redis工作线程在发现有读写事件发生时，工作线程会分配IO线程去处理对应客户端的读写操作，首先进行并行输入，然后在工作线程中完成计算后，再并行输出。极大的提高了处理事件的效率，当处理时间的效率提升时，内核就可以更快地接收新的客户端，这样整体的吞吐量就会提升。

### 总结

Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。之所以这么设计是不想因为多线程而变得复杂，需要去控制 key、lua、事务，LPUSH/LPOP 等等的并发问题。

第一步，从内核把数据搬运到程序里

第二步，把搬运回来的数据进行计算

另外，多线程IO默认也是不开启的，需要再配置文件中配置

如果担心数据库压力太大，导致redis挂了的话。尽量去分片，把数据拆到读redis里面

### redis单线程快，为什么mysql不使用呢？

因为mysql是关系型数据库，他俩作用不一样

### 类似问题

**redis 存在线程安全问题吗？**

redis可以保证内部串行，外包需要在代码层面处理

## 缓存击穿、缓存穿透、缓存雪崩

击穿、穿透、雪崩都是为了避免DB无效，重复请求

![image-20230207220905827](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230207220905827.png)

### 穿透

#### 问题描述

在redis和数据库中都**没有对应的数据**，查询数据时，就会穿过redis，从而加大DB的访问压力。导致查询有效数据的响应变慢。

黑客可以通过这种方法工具数据库服务器

#### 解决方法

**key null**

做**key null**(比较浪费空间)，如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存。

因为redis的串行，请求key null的这些请求时，请求就会串行后一个一个去访问数据库，对redis和DB的压力都会增大。为了减轻redis和DB的压力，可以在请求redis之前设置一把锁，将压力转到代码层面。

![image-20220220124407528](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220124407528.png)

**布隆过滤器**



### 击穿

热点key过期，或这个key**没有被缓存**过（就压根没有被访问过），这时突然大量的并发访问这个key，因为redis中没有缓存，所以大量的请求涌向数据库，导致数据库崩了。

**解决方法**

和上面解决一样，可以加个锁

分散过期时间

### 雪崩

很多key集中过期了

和上面解决一样，每个redis都可以加个锁（AKL分治，每一个锁是隔离的），或者使用第三方锁提供扩展能力。

## 布隆过滤器

解决穿透问题——redis和DB都没有的情况，解决方式：布隆过滤器，

![image-20230210201755749](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230210201755749.png)

布隆过滤器会在redis中开辟一个bitmap二进制数组，并将值全部设置为1，当数据经过布隆过滤器时会通过若干个hash散列算法，数据通过这些散列算法后将对应位置的bitmap数组值改为1，当后续要查询数据时，同样会通过若干个hash算法，然后到bit数组中对应的位置去查询，该位置是否为1，如果查询得到的值都是1（查询的数据很有可能存在与redis中，因为有可能是其他数据经过hash算法后计算修改的；也可能存在都有但是不存在的情况，很少）；如果查询的结果中一个0，就说明一定不存在。

## 缓存如何回收/淘汰的?

### 回收——Redis是怎么删除过期key的

**内存空间还很充足，只是回收没有用到的**

1. 后台在轮询时，会分批分段的删除过期的key
2. 请求的时候会判断是否已经过期了

尽量的把内存无用空间回收回来

### 淘汰

**内存空间不足时，需要腾出空间**

**LRU（按照最少使用）**

`LRU` 会把所有的数据组织成一个链表，两段分别表示最近使用和最久使用（时间戳+数据）。Redis 默认会记录每个数据的最近一次访问的时间戳。

- 当数据有冷热区分时，使用allkeys-lru策略，更好的利用lru算法
- 当数据没有明显热度区别时，使用 allkeys-random 策略，随机淘汰
- 当业务中有置顶业务时，这些数据最好不要设置过期时间，并采用lru策略

**LFU**

`LFU` 缓存策略是在 `LRU` 策略基础上，为每个数据增加了一个「计数器」，来统计这个数据的访问次数。

- 会根据计数器将访问次数最低的淘汰
- 如果两个数据访问次数一致，会比较这两个数据的访问时效（即选出上一次访问时间更久的数据）淘汰

**淘汰策略**

- volatile-lru：使用LRU算法移除key，**只对设置了过期时间的键**；（最近最少使用）

- allkeys-lru：在所有集合key中，使用LRU算法移除key

- volatile-random：在过期集合中移除随机的key，**只对设置了过期时间的键**

- allkeys-random：在所有集合key中，移除随机的key

- volatile-ttl：移除那些TTL值最小的key，即那些最近要过期的key

- noeviction：不进行移除。针对写操作，只是返回错误信息

## 缓存预热？

提前把热点数据存入到redis中

个人感觉根本没必要做预热，因为没有意义。+ 击穿、雪崩

## redis与DB的一致性问题

关于一致性问题，首先就是100%的一致性解决方案我认为是没有的，但是我们可以趋近于这个100%。因为在单机的读写操作时，内存往磁盘同步时，也会有存在一致性问题（缓存刷盘时宕机，数据就会丢失）。

1. 恶心点：可以使用**分布式事务**来解决（意义不大，为了解决一个问题引入更恶心的问题，仅仅适用于读多，写稀有）
2. 首先redis是缓存，一致性是有时差的
3. 还是减少数据库的操作，可以加锁
4. 真的要落地，Cannal（订阅MySQL的binlog，伪装成从节点，把binlog 文件转换成想要的数据，用mq异步形式同步到redis当中，这就是阿里cannal框架底层实现的原理）

### 读取数据一致性

mysql一定会慢

让读写操作尽量发生在redis上

![image-20220220141802743](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220141802743.png)

### 有数据修改的读取数据一致性

最好从mysql读，然后同步到redis

可以监控binlog

![image-20220220143137336](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220143137336.png)

如果先修改数据库，再修改redis，会造成短暂的不一致性，如果数据库修改后宕机，redis的数据就会不一致。

canal可以伪装成slave从mysql服务器中读取bin log然后将数据通过kafka或者MQ，同步到redis/es中

https://blog.csdn.net/weixin_43989347/article/details/124046941

### 完全异步的数据一致性

![image-20220220143416670](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220143416670.png)

降低写操作的速度，将同步的操作交给MQ的消费者来完成

## 主从不一致问题

1. redis默认是弱一致性，异步的同步(肯定会有不一致的发生)
2. 锁不能用主从（单实例/分片集群/redlock）==>redisson
3. 在配置中，redis的后续版本提供了必须有多少个Client链接能同步，你可以配置同步因子，趋向于强一致性
4. wait 2 5000 小心
5. 3、4点有点违背redis的初衷了

## 双写不一致问题

### redis和DB的数据关系

**po和vo、bo**

PO：是直接从数据库映射出来的

VO、BO：是多表间联合映射的

**数据状态变换**

1. 加减操作，集合的增减
   1. ![image-20230210154533265](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230210154533265.png)
   2. 增减在同步的过程中，顺序可能会被打乱，但是结果是一致的
2. po、vo、bo的加减操作的最终也是一一致的
   1. ![image-20230210154720862](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230210154720862.png)
   2. 最终的结果还是一致的
3. 状态的覆盖
   1. ![image-20230210154808270](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230210154808270.png)
   2. 数据添加时的顺序出错，就会导致数据的不一致问题

### 解决措施

读：先读缓存，有直接取，没有去数据库查，然后更新缓存（击穿、穿透、雪崩、预热）

写：

#### 先写数据库，后写缓存

状态的覆盖覆盖

**问题**

数据库更新成功了，缓存更新失败了，就会造成不一致

**解决方法**

可以在缓存上加上过期时间

#### 先写数据库，后删缓存

因为不能同时满足更新缓存和DB

**问题**

缓存更新失败

**问题**

并发读，在数据库数据修改前读到了老的数据

#### 延时双删

**描述**

先改数据库，删除缓存，过一段时间再删除一次

**问题**

也存在缓存更新失败，读到了还是老的

 

**引入中台**

![image-20230210163253795](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230210163253795.png)

因为在多服务间调用时，接口服务不知道下层服务是否做过redis处理，这时如果对数据进行redis操作，就会导致数据的不一致。因此为了统一的管理这些接口和服务，就有了中台。

将redis和DB的操作都封装到中台中进行调度，中台会将对外的接口进行封装，对外提供一套统一的API。有了中台就可以快速搭建系统。

![image-20230210163025159](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230210163025159.png)

**由此我们可见，在现在的开发中缓存和数据库是不能被拆开的**

+++

#### 先写缓存，后写数据库

**问题**

bug——一定要规避状态的覆盖问题，不能有顺序依赖性

先改缓存，推送MQ，MQ修改DB

**CQRS**

**依赖于一个结论，redis是mysql的缓存，应该是一个项目组自主维护先写缓存，后写数据库**

为什么希望是通过先写缓存后写数据库来解决这类问题？

很重要的原因是——数据库的写操作很慢（慢的原因：磁盘IO、**随机写**）。redis这种基于内存的大多数都是直接在磁盘上顺序写，而数据库他的索引结构导致他在存储数据的时候是分散的，如果你对一个BO/VO进行操作很有可能影响到多个PO。因此应尽可能的先写缓存再写数据库，但是这种情况十分有限，仅限于顺序打乱后不影响最终结果的。（适用于集合的增加，数值的增减）

![image-20230210170400090](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230210170400090.png)

**canal——基于cqrs**

他的成本很高，很有局限性

基本上不会用

### 分布式锁

![image-20230210192344325](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230210192344325.png)

解决击穿、穿透、雪崩时，redis失效，导致DB压力过大的问题

1. 没读取到
2. 抢锁
3. 数据库查
4. 同步

## 描述一下redis持久化

### 原理

1. 当前进程阻塞服务
2. 异步后台进程完成持久
3. fork+cpoy on wirte(cow)
   1. Fork的作用是复制一个与当前进程一样的进程。新进程的**所有数据（**变量、环境变量、程序计数器等） **数值都和原进程一致**，但是是一个全新的进程，并**作为原进程的子进程**
   2. 写时复制技术
   3. **一般情况父进程和子进程会共用同一段物理内存**

### 方式

1. RDB， AOF;主从同步也算持久化;
2. 高版本:开启AOF，AOF是可以通过执行日志得到全部内存数据的方式，但是追求性能:
   1. 体积变大，重复无效指令 重写，后台用线程把内存的kv生成指令写个新的aof
   2. 4.x新增更有性能模式：**把重写方式换成直接RDB放到aof文件的头部，比2.1的方法快**
      **了，再追加日志**

#### RDB（Redis DataBase）

在指定的时间间隔内将内存中的数据集快照写入磁盘， 也就是行话讲的Snapshot快照，它恢复时是将快照文件直接读到内存里

**RDB的缺点是最后一次持久化后的数据可能丢失。、**

**流程**

![image-20220220154204416](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220154204416.png)

**优势**

节约磁盘空间

恢复速度快

对数据完整性和一致性要求不高更适合使用

**劣势**

fork时较占内存（看copy文件的大小）

如果redis以外down掉了，就会丢失最后一次快照的所有修复

#### AOF（Append Only File）

**以日志的形式来记录每个写操作（增量保存）**，将Redis执行过的所有写指令记录下来**(读操作不记录)， 只许追加文件但不可以改写文件**，

**流程**

![image-20220220155052067](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220155052067.png)

**重写流程**

![image-20220220155350985](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220155350985.png)

**优势**

备份机制更稳健，丢失数据概率更低。

可读的日志文本，通过操作AOF稳健，可以处理误操作。

**劣势**

比起RDB占用更多的磁盘空间。

恢复备份速度要慢。

偶尔有bug

+++

**如果对数据不敏感，可以选单独用RDB。**

**不建议单独用 AOF，因为可能会出现Bug。**

**AOF和RDB同时开启，系统默认取AOF的数据（数据不会存在丢失）**

## redis事务

Multi、Exec、discard

![image-20220220153739970](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20220220153739970.png)

从输入Multi命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。

组队的过程中可以通过discard来放弃组队。  

事务的执行时期是原子的，失败就是失败了，继续执行其他指令，没有回滚

-  单独的隔离操作 
   - 事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 

-  没有隔离级别的概念 
   - 队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行

-  不保证原子性 
   - 事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 

## setnx

在 Redis 里，所谓 SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，若给定的 key 已经存在，则 SETNX 不做任何动作。

**SETNX key value**

返回值

设置成功，返回 1 。

设置失败，返回 0 。

示例

```
redis> EXISTS job                # job 不存在
(integer) 0

redis> SETNX job "programmer"    # job 设置成功
(integer) 1

redis> SETNX job "code-farmer"   # 尝试覆盖 job ，失败
(integer) 0

redis> GET job                   # 没有被覆盖
"programmer"
```

将 key 的值设为 value ，当且仅当 key 不存在。
若给定的 key 已经存在，则 SETNX 不做任何动作。

1. 好东西、原子（不存在的情况下完成创建）
2. 如果要做分布式锁，就要用set k v nx ex (不存在、过期时间、避免死锁)

https://blog.csdn.net/liu59412/article/details/104603041

## redis快的原因

1. 完全基于内存，数据也都在内存，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
2. 结构简单，对数据的操作也简单
3. 整体采用单线程，不用考虑锁，多线程带来的CPU消耗等问题
4. 多路复用IO模型，非阻塞IO（NIO）,计算向数据移动（在IO上优化）
5. 数据结构：zipList、QuickList
6. 用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

## redis中的客户端怎么实现list的使用

**ziplist**

**quicklist**

## 如果把一个队列存放到redis中，该用什么方法保证先进先出

情况1，数据数量不多，可以用

情况2，数据量多，但存的数据是激活码这样简单值一类，可以用。

情况3，list存的是要获取数据的索引，大量数据的值已经存在redis的KV结构中。

这时候，如果数据每次获取下一个数据都要执行redis的hash查找（O(1)）然后redis的list从头或者末尾出一个。经过网络IO返回，Java程序在用出来的key去请求redis去get(key) （O(1)）。这里是两次网络IO或者进程间的IO。

这时候，可以不用redis的list存索引而只是用redis大的KV哈希结构存键值。

①用Java的队列先进先出获取下一个key或者

**②使用预先规定好的键生成的规则，让键是有规则有顺序的，比如自增ID，然后每次获取都是ID++，而直接从`redis.get(ID.next());`来获取值。**

最后一种就是最高效的办法，为了特殊场景的高效出队列而设计。但是如果只是一般的数据量，使用redis的list也未尝不可。

## 分布式锁

锁商品时，将商品id作为主键存到redis的一行记录中

锁住商品后（设置分布式锁），修改商品总数（对被锁的事务进行相应的业务操作），释放锁（业务操作完毕）

释放锁的方式：

1. 设置开始时间和结束时间
2. 定时任务
3. 为了防止超时而造成资源的浪费，也可以设置动态数据，设置一个线程定期来查看数据是否在被修改，若长时间内动态数据没有被修改，则删除锁

**引入redis**

![image-20230208212918784](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230208212918784.png)

两个线程竞争key，当一个线程获取到后，开一个异步线程去实时查看如果任务没有结束，就为该锁续期；当任务结束后，判断是否是否为当前线程，是的话删除（必要时引入lua脚本）

**主从问题**

为了防止单机故障，因此需要引入集群，但引入集群后又会引发主从不一致问题

![image-20230208213959003](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230208213959003.png)

服务1获取Master的锁，锁的信息还没有同步到salve中时，服务2获取slave的锁，这时也可以获取成功。就会导致两个服务获取到了同一把锁。

为了解决这种问题，人们想出来——红锁。

**红锁**

![image-20230208214911396](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230208214911396.png)

设置奇数台redis集群，线程1去获取redis中的锁，线程2也去获取redis中的锁，在获取到锁之后，再去尝试获取第二台redis中的锁（相当于两个线程对redis资源的争抢），最终哪个线程获取到的redis多，哪个线程就获取到了锁。

如果是偶数台，且刚好都获取到了一半，那就都不要获取到锁，因为没有获取到锁，就没法操作数据，没法操作数据就保证了数据的一致性。

加锁的目的是为了互斥

**红锁的缺点**

![image-20230208220109555](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230208220109555.png)

当业务1获取到获取到锁后，redis3重启了/宕机重启了，之前的锁信息就没了，业务2尝试获取时，也会获取到锁。

解决方法：延时启动，24小时重启一次（避免在获取到锁的时候重启）

**stw的问题**

![image-20230208220621082](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230208220621082.png)

jvm发生GC的stw时，业务1短暂的失去了锁，业务2趁这个时间获取到了锁，两个线程就可以一起操作数据了。

解决方法：鸵鸟算法

**引入zk+mysql+乐观锁**

![image-20230208221344985](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230208221344985.png)

A线程获取后，设置key=000，发生stw。B线程获取到了锁，设置key=001。当Astw结束后，去数据库查询，发现没有000，于是回滚改回000。

### 分布式锁的问题

![image-20230210173928677](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230210173928677.png)

抢到锁了

**死锁**

clint连接到redis后，redis使用ex或者nx获取到锁，但是一直没有释放，就会造成死锁

解决方法：设置过期时间

**重复锁**

设置过期时间后，时间到了，但是业务没有结束，另一个线程抢到锁

解决方式：看门狗——设置dog续期

**uuid**

非原子性

解决方式：lua脚本

**实现可重入锁**

hash(名字key、归属uuid、计数器)+lua

**redisson实现了**

### 性能问题

没有抢到锁的线程

**轮询cas的方式抢锁**

**受，回调方式——基于redis的发布订阅，订阅redis自身的事件**

用另一个线程去订阅redis的事件，当发生过删除事件时，就表示线程已经被腾出了，就会通知当前的等待线程去抢锁

**redisson实现了**

### 单点故障，可靠性问题

**高可靠集群**

使用哨兵，开启主从同步，会有延迟，不一致，容易发生重复锁

**分片集群**

解决的是压力问题

**红锁**

实现是在clint端实现的，附加到redis服务中去。

问题：容易发生并发抢锁失败

优化：有序抢锁

## 分布式事务

**2pc**

![image-20230208225050480](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230208225050480.png)

协调者先去判断两个服务是否能够执行成功，两个服务去执行后，都会给协调者发送通知，当俩服务都ok，协调者会给两个服务发送执行命令。主要分为投票阶段和执行阶段

**如果两个服务中有一个失联了该怎么办？**

![image-20230208225357939](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230208225357939.png)



采用人工补偿的方式

例如上图中采用定时任务的方式去数据库中查看是否有对应的数据，如果没有就回滚。

**3pc**

2pc有一个弊端就是，协调者一旦宕机，整个服务就寄了

因此3pc中不仅服务会有超时机制，协调者也会有超市机制。

![image-20230208224847005](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230208224847005.png)

can commit阶段回去尝试执行sql，如果可以执行，就执行pre commit，此时sql会真正被执行，执行成果后执行do commit提交事务。do commit只会提交，除非接收到pre commit的回滚请求。

## redis的集群方案

缓存更多的是用来提高性能问题

主从复制，手动切换

带有哨兵的主从复制集群

客户端路由索引的分片集群

使用中间件代理层的分片集群

redis实现的cluster分片集群

### 分片集群

主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：

- **海量数据存储问题**
- **高并发写的问题**

使用分片集群可以解决上述问题，如图:

![image-20230209093454991](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230209093454991.png)

分片集群特征：
集群中有多个master，每个master保存不同数据

每个master都可以有多个slave节点

master之间通过ping监测彼此健康状态

客户端请求可以访问集群任意节点，最终都会被转发到正确节点

散列插槽
Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到：

![image-20230209093548002](redis%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20230209093548002.png)

数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值

### 为什么槽是16384？

1. 在redis节点发送心跳包时需要把所有的槽信息放到这个心跳包里，以便让节点知道当前集群信息，在发送心跳包时使用char进行bitmap压缩后是2k（16384÷8÷1024=2kb），也就是说使用2k的空间创建了16k的槽数。虽然使用CRC16算法计算出最多可以有65535个槽，但是65535个槽的话，压缩后就是8k，信条信息就太大了，作者认为不值得
2. 再者redis的节点不可能部署超过1000台，所以16384个槽就够用了

## redis单机TPS/QPS是多少？

和value体积和value类型是有关系的，4W左右

## 解决了项目什么问题？

1. 读多写少的情况下
2. 
3. 无关紧要的数据可以放到redis中——为了减轻数据库的压力
4. 动静分离的
   1. 静态数据——字典（地理位置，基本不会变得这种数据）
   2. 聚合数据——通过计算得到的数据（读多写少的数据）
   3. 涉及到一致性的问题（秒杀项目）

## reids内存不足了，也不给买新的redis，要求不能转存，还要保证redis性能

1. 压缩
2. vaue类型的梳理（string->hash）
3. redis有一个特质，VM的配置，可以将数据写到磁盘（冷数据写到磁盘，热数据写到内存）

## 存储+缓存时，redis怎么设置？

1. redis淘汰机制

2. LRU/LFU

   

3. **操作上有要求，认为可以淘汰的数据，都要加上过期时间**

## redis是否使用主从复制和读写分离？

1. 读写分离是有延时的，所以查询一致性相关的数据时，尽量不要使用主从复制
2. 没有一致性要求的数据可以
3. 完全不会调整的数据所谓缓存时，可以使用主存分离

**哨兵的主从，从是怎么发现的，动态扩展从节点，怎么改配置，重启集群？**

哨兵只需要配置master，通过发布订阅，哨兵之间就会发现（所有的哨兵不需要配置别的哨兵，只需要配置master就可以）

通过master的info relica（从节点的信息）用来切换

